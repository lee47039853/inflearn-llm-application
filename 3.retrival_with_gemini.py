#!/usr/bin/env python3
"""
RAG (Retrieval-Augmented Generation) ì‹œìŠ¤í…œ ì˜ˆì œ
ë¬¸ì„œ ê¸°ë°˜ ì§ˆì˜ì‘ë‹µ ì‹œìŠ¤í…œ - ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨
"""

from langchain_community.document_loaders import Docx2txtLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from dotenv import load_dotenv
from langchain_google_genai import GoogleGenerativeAIEmbeddings
from langchain_community.embeddings import HuggingFaceEmbeddings
import os
from langchain_chroma import Chroma
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain import hub
from langchain.chains import RetrievalQA
from pathlib import Path
import shutil
import logging
import re
from typing import List, Dict, Tuple, Optional
from datetime import datetime

class EnhancedRAGSystem:
    """í–¥ìƒëœ RAG ì‹œìŠ¤í…œ í´ë˜ìŠ¤"""
    
    def __init__(self, database, llm):
        self.database = database
        self.llm = llm
    
    def search_documents(self, query: str, top_k: int = 5) -> List[Tuple]:
        """ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰"""
        try:
            results = self.database.similarity_search_with_score(query, k=top_k)
            return results
        except Exception as e:
            print(f"âš ï¸  ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

class ConversationHistory:
    """ëŒ€í™” íˆìŠ¤í† ë¦¬ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, max_history: int = 10):
        self.history = []
        self.max_history = max_history
        self.current_context = ""
        self.history_enabled = True  # íˆìŠ¤í† ë¦¬ í™œì„±í™” ìƒíƒœ
    
    def add_exchange(self, question: str, answer: str, retrieved_docs: List = None):
        """ì§ˆë¬¸-ë‹µë³€ êµí™˜ ì¶”ê°€"""
        if not self.history_enabled:
            return  # íˆìŠ¤í† ë¦¬ê°€ ë¹„í™œì„±í™”ëœ ê²½ìš° ì €ì¥í•˜ì§€ ì•ŠìŒ
        
        exchange = {
            'timestamp': datetime.now().isoformat(),
            'question': question,
            'answer': answer,
            'retrieved_docs': retrieved_docs if retrieved_docs else [],
            'context_summary': self._extract_context(answer)
        }
        
        self.history.append(exchange)
        
        # ìµœëŒ€ íˆìŠ¤í† ë¦¬ ìˆ˜ ìœ ì§€
        if len(self.history) > self.max_history:
            self.history.pop(0)
        
        # ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
        self._update_context()
    
    def _extract_context(self, answer: str) -> str:
        """ë‹µë³€ì—ì„œ í•µì‹¬ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ë°©ë²• ì‚¬ìš© ê°€ëŠ¥)
        keywords = ['ì†Œë“ì„¸', 'ì„¸ìœ¨', 'ê³µì œ', 'ê³¼ì„¸í‘œì¤€', 'ì—°ë´‰', 'ê±°ì£¼ì']
        context_parts = []
        
        for keyword in keywords:
            if keyword in answer:
                # í‚¤ì›Œë“œ ì£¼ë³€ ë¬¸ì¥ ì¶”ì¶œ
                sentences = answer.split('.')
                for sentence in sentences:
                    if keyword in sentence:
                        context_parts.append(sentence.strip())
        
        return '. '.join(context_parts[:3])  # ìµœëŒ€ 3ê°œ ë¬¸ì¥
    
    def _update_context(self):
        """ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸"""
        if not self.history:
            self.current_context = ""
            return
        
        # ìµœê·¼ 3ê°œ êµí™˜ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ê²°í•©
        recent_contexts = []
        for exchange in self.history[-3:]:
            if exchange['context_summary']:
                recent_contexts.append(exchange['context_summary'])
        
        self.current_context = " ".join(recent_contexts)
    
    def get_context_for_query(self, new_question: str) -> str:
        """ìƒˆ ì§ˆë¬¸ì— ëŒ€í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        if not self.history_enabled or not self.history:
            return new_question
        
        # ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ì™€ ìƒˆ ì§ˆë¬¸ ê²°í•©
        context_query = f"ì´ì „ ëŒ€í™”: {self.current_context}\n\nìƒˆ ì§ˆë¬¸: {new_question}"
        return context_query
    
    def show_history(self, limit: int = 5):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ í‘œì‹œ"""
        if not self.history_enabled:
            print("ğŸš« ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return
        
        if not self.history:
            print("ğŸ“ ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\nğŸ“ ìµœê·¼ ëŒ€í™” íˆìŠ¤í† ë¦¬ (ìµœëŒ€ {limit}ê°œ):")
        print("=" * 60)
        
        for i, exchange in enumerate(self.history[-limit:], 1):
            print(f"\nğŸ’¬ êµí™˜ {i}:")
            print(f"  ì§ˆë¬¸: {exchange['question']}")
            print(f"  ë‹µë³€: {exchange['answer'][:100]}...")
            print(f"  ì»¨í…ìŠ¤íŠ¸: {exchange['context_summary']}")
            print("-" * 40)
        
        print("=" * 60)
    
    def clear_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"""
        removed_count = len(self.history)
        self.history = []
        self.current_context = ""
        print(f"ğŸ—‘ï¸  ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤. (ì œê±°ëœ ëŒ€í™”: {removed_count}ê°œ)")
    
    def reset_conversation(self):
        """ëŒ€í™” ì™„ì „ ì´ˆê¸°í™” (íˆìŠ¤í† ë¦¬ + ì»¨í…ìŠ¤íŠ¸)"""
        removed_count = len(self.history)
        self.history = []
        self.current_context = ""
        self.history_enabled = True  # ê¸°ë³¸ ìƒíƒœë¡œ ë³µì›
        print(f"ğŸ”„ ëŒ€í™”ê°€ ì™„ì „íˆ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"  - ì œê±°ëœ ëŒ€í™”: {removed_count}ê°œ")
        print(f"  - íˆìŠ¤í† ë¦¬ ìƒíƒœ: í™œì„±í™”ë¡œ ë³µì›")
        print(f"  - ì»¨í…ìŠ¤íŠ¸: ì´ˆê¸°í™”ë¨")
    
    def clear_and_disable(self):
        """íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” í›„ ë¹„í™œì„±í™”"""
        removed_count = len(self.history)
        self.history = []
        self.current_context = ""
        self.history_enabled = False
        print(f"ğŸš« ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ì´ˆê¸°í™”ë˜ê³  ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
        print(f"  - ì œê±°ëœ ëŒ€í™”: {removed_count}ê°œ")
        print(f"  - í–¥í›„ ëŒ€í™”ëŠ” ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    def disable_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ë¹„í™œì„±í™”"""
        self.history_enabled = False
        print("ğŸš« ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def enable_history(self):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ í™œì„±í™”"""
        self.history_enabled = True
        print("âœ… ëŒ€í™” íˆìŠ¤í† ë¦¬ê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def remove_last_exchange(self):
        """ë§ˆì§€ë§‰ ëŒ€í™” êµí™˜ ì œê±°"""
        if self.history:
            removed = self.history.pop()
            self._update_context()
            print(f"ğŸ—‘ï¸  ë§ˆì§€ë§‰ ëŒ€í™”ê°€ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤:")
            print(f"  ì§ˆë¬¸: {removed['question']}")
            print(f"  ë‹µë³€: {removed['answer'][:50]}...")
        else:
            print("âŒ ì œê±°í•  ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def remove_exchange_by_index(self, index: int):
        """ì¸ë±ìŠ¤ë¡œ íŠ¹ì • ëŒ€í™” êµí™˜ ì œê±°"""
        if 0 <= index < len(self.history):
            removed = self.history.pop(index)
            self._update_context()
            print(f"ğŸ—‘ï¸  ëŒ€í™” {index + 1}ì´ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤:")
            print(f"  ì§ˆë¬¸: {removed['question']}")
            print(f"  ë‹µë³€: {removed['answer'][:50]}...")
        else:
            print(f"âŒ ì¸ë±ìŠ¤ {index + 1}ì˜ ëŒ€í™”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    def get_history_status(self) -> Dict:
        """íˆìŠ¤í† ë¦¬ ìƒíƒœ ì •ë³´ ë°˜í™˜"""
        return {
            'enabled': self.history_enabled,
            'count': len(self.history),
            'max_history': self.max_history,
            'has_context': bool(self.current_context)
        }
    
    def get_relevant_context(self, new_question: str) -> str:
        """ìƒˆ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ì´ì „ ì»¨í…ìŠ¤íŠ¸ ì°¾ê¸°"""
        if not self.history_enabled or not self.history:
            return ""
        
        # ìƒˆ ì§ˆë¬¸ì˜ í‚¤ì›Œë“œ ì¶”ì¶œ
        question_keywords = self._extract_keywords(new_question)
        
        relevant_contexts = []
        for exchange in self.history:
            # ì´ì „ ì§ˆë¬¸ì´ë‚˜ ë‹µë³€ì—ì„œ ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆëŠ”ì§€ í™•ì¸
            exchange_text = f"{exchange['question']} {exchange['answer']}"
            exchange_keywords = self._extract_keywords(exchange_text)
            
            # í‚¤ì›Œë“œ ê²¹ì¹¨ í™•ì¸
            common_keywords = set(question_keywords) & set(exchange_keywords)
            if common_keywords:
                relevant_contexts.append(exchange['context_summary'])
        
        return " ".join(relevant_contexts[-2:])  # ìµœê·¼ 2ê°œ ê´€ë ¨ ì»¨í…ìŠ¤íŠ¸
    
    def _extract_keywords(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        keywords = ['ì†Œë“ì„¸', 'ì„¸ìœ¨', 'ê³µì œ', 'ê³¼ì„¸í‘œì¤€', 'ì—°ë´‰', 'ê±°ì£¼ì', 'ì¢…í•©ì†Œë“', 'ë²•ì¸ì„¸', 'ë¶€ê°€ê°€ì¹˜ì„¸']
        found_keywords = []
        
        for keyword in keywords:
            if keyword in text:
                found_keywords.append(keyword)
        
        return found_keywords

def check_existing_database():
    """ê¸°ì¡´ Chroma ë°ì´í„°ë² ì´ìŠ¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
    chroma_dir = Path("./chroma")
    if chroma_dir.exists() and any(chroma_dir.iterdir()):
        return True
    return False

def clear_database():
    """ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ"""
    chroma_dir = Path("./chroma")
    if chroma_dir.exists():
        shutil.rmtree(chroma_dir)
        print("ğŸ—‘ï¸  ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

def get_user_choice():
    """ì‚¬ìš©ìë¡œë¶€í„° ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬ ë°©í–¥ ì„ íƒë°›ê¸°"""
    print("\nğŸ“‹ ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬ ì˜µì…˜:")
    print("1. ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì¬ì‚¬ìš© (ë¹ ë¦„)")
    print("2. ìƒˆë¡œìš´ ë°ì´í„°ë² ì´ìŠ¤ ìƒì„± (ì²˜ìŒ ì‹¤í–‰)")
    print("3. ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì‚­ì œ í›„ ìƒˆë¡œ ìƒì„±")
    
    while True:
        try:
            choice = input("\nì„ íƒí•˜ì„¸ìš” (1-3): ").strip()
            if choice in ['1', '2', '3']:
                return choice
            else:
                print("âŒ 1, 2, 3 ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")
        except KeyboardInterrupt:
            print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            exit()





def main():
    # LangChain ë””ë²„ê·¸ ë¡œê¹… í™œì„±í™” (ì„ íƒì‚¬í•­)
    # logging.basicConfig(level=logging.DEBUG)
    
    # .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
    load_dotenv()
    
    # Google API í‚¤ í™•ì¸
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        print("âŒ GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   .env íŒŒì¼ì— GOOGLE_API_KEY=your_api_key_hereë¥¼ ì¶”ê°€í•˜ì„¸ìš”.")
        return
    
    try:
        # ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ í™•ì¸
        has_existing_db = check_existing_database()
        
        if has_existing_db:
            choice = get_user_choice()
            
            if choice == '3':
                clear_database()
                has_existing_db = False
        else:
            print("ğŸ“„ ìƒˆë¡œìš´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        
        # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
        print("\nğŸ”§ ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
        
        # ì‚¬ìš©ìë¡œë¶€í„° ì„ë² ë”© ëª¨ë¸ ì„ íƒë°›ê¸°
        print("\nğŸ“Š ì„ë² ë”© ëª¨ë¸ ì„ íƒ:")
        print("1. í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ (ko-sroberta-multitask) - ì¶”ì²œ")
        print("2. Google Gemini ì„ë² ë”© (ê¸°ì¡´)")
        
        while True:
            try:
                embedding_choice = input("\nì„ íƒí•˜ì„¸ìš” (1-2): ").strip()
                if embedding_choice in ['1', '2']:
                    break
                else:
                    print("âŒ 1, 2 ì¤‘ì—ì„œ ì„ íƒí•˜ì„¸ìš”.")
            except KeyboardInterrupt:
                print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                exit()
        
        if embedding_choice == '1':
            # í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© ëª¨ë¸ ì‚¬ìš©
            print("ğŸ‡°ğŸ‡· í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
            model_name = "jhgan/ko-sroberta-multitask"
            model_kwargs = {'device': 'cpu'}
            encode_kwargs = {'normalize_embeddings': True}
            embedding = HuggingFaceEmbeddings(
                model_name=model_name,
                model_kwargs=model_kwargs,
                encode_kwargs=encode_kwargs
            )
            print("âœ… í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
        else:
            # Google Gemini ì„ë² ë”© ì‚¬ìš© (ê¸°ì¡´)
            print("ğŸŒ Google Gemini ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
            embedding = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
            print("âœ… Google Gemini ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì™„ë£Œ") 

        # Chroma ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
        database = Chroma(
            collection_name='chroma-tax', 
            persist_directory="./chroma", 
            embedding_function=embedding
        )

        # ë°ì´í„°ë² ì´ìŠ¤ ì²˜ë¦¬
        if has_existing_db and choice == '1':
            print("ğŸ“š ê¸°ì¡´ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¬ì‚¬ìš© ì¤‘...")
            
            # ê¸°ì¡´ ì»¬ë ‰ì…˜ì˜ ë¬¸ì„œ ìˆ˜ í™•ì¸
            try:
                collection_count = database._collection.count()
                print(f"âœ… ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ {collection_count}ê°œì˜ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"âš ï¸  ê¸°ì¡´ ë°ì´í„°ë² ì´ìŠ¤ ì •ë³´ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
                print("   ìƒˆë¡œìš´ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                has_existing_db = False
        
        if not has_existing_db or choice == '2':
            print("ğŸ“„ ë¬¸ì„œ ë¡œë”© ì¤‘...")
            
            # í…ìŠ¤íŠ¸ ë¶„í•  ì„¤ì •
            text_splitter = RecursiveCharacterTextSplitter(
                chunk_size=1500,
                chunk_overlap=200,
            )

            # Word ë¬¸ì„œ ë¡œë“œ ë° ë¶„í• 
            loader = Docx2txtLoader("./tax.docx")
            document_list = loader.load_and_split(text_splitter=text_splitter)
            
            print(f"âœ… {len(document_list)}ê°œì˜ ë¬¸ì„œ ì²­í¬ë¡œ ë¶„í•  ì™„ë£Œ")

            # ë¬¸ì„œë¥¼ ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
            database.add_documents(document_list)
            print("âœ… ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì— ë¬¸ì„œ ì €ì¥ ì™„ë£Œ")

        # LLM ëª¨ë¸ ì´ˆê¸°í™”
        llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash', temperature=0.9)
        prompt = hub.pull("rlm/rag-prompt")

        # RAG ì²´ì¸ ìƒì„±
        qa_chain = RetrievalQA.from_chain_type(
            llm, 
            retriever=database.as_retriever(),
            chain_type_kwargs={"prompt": prompt}
        )

        # í–¥ìƒëœ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        print("\nğŸ”§ í–¥ìƒëœ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
        enhanced_rag = EnhancedRAGSystem(database, llm)
        print("âœ… í–¥ìƒëœ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
        conversation_history = ConversationHistory()

        # ì§ˆë¬¸-ë‹µë³€ ë£¨í”„
        while True:
            # ì‚¬ìš©ìë¡œë¶€í„° ì§ˆë¬¸ ì…ë ¥ë°›ê¸°
            print("\nğŸ¤– ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
            print("   (ì—¬ëŸ¬ ì¤„ ì…ë ¥ ê°€ëŠ¥: ê° ì¤„ ì…ë ¥ í›„ Enter, 'END'ë¡œ ì™„ë£Œ, 'CANCEL'ë¡œ ì·¨ì†Œ)")
            print("   (ì˜ˆ: ì œ 55ì¡°ì˜ ì¢…í•©ì†Œë“ ê³¼ì œí‘œì¤€ ê¸°ì¤€ìœ¼ë¡œ ê±°ì£¼ìì˜ ì—°ë´‰ì´ 5ì²œë§Œì› ì¸ ê²½ìš°")
            print("        í•´ë‹¹ ê±°ì£¼ìì˜ ì†Œë“ì„¸ëŠ” ì–¼ë§ˆì¸ê°€ìš”?)")
            print("   (ì…ë ¥ ì¤‘ 'CLEAR'ë¡œ ë‚´ìš© ì§€ìš°ê¸°, 'CANCEL'ë¡œ ì…ë ¥ ì·¨ì†Œ)")
            print("   (ì…ë ¥ ì¤‘ íˆìŠ¤í† ë¦¬ ì œì–´: disable_history, enable_history, clear_history, reset_conversation, clear_and_disable)")
            print("   (ì¢…ë£Œí•˜ë ¤ë©´ 'quit' ë˜ëŠ” 'exit' ì…ë ¥)")
            print("   (ëŒ€í™” íˆìŠ¤í† ë¦¬: show_history, clear_history, show_context)")
            print("   (íˆìŠ¤í† ë¦¬ ì œì–´: disable_history, enable_history, remove_last, remove_history:ë²ˆí˜¸, history_status)")
            print("   (ì™„ì „ ì´ˆê¸°í™”: reset_conversation, clear_and_disable)")
            print("-" * 50)
            
            try:
                # ì—¬ëŸ¬ ì¤„ ì§ˆë¬¸ ì…ë ¥ ë°›ê¸°
                print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì—¬ëŸ¬ ì¤„ ê°€ëŠ¥, 'END'ë¡œ ì…ë ¥ ì™„ë£Œ, 'CANCEL'ë¡œ ì·¨ì†Œ):")
                query_lines = []
                line_count = 0
                
                while True:
                    line_count += 1
                    line = input(f"[{line_count}]> ").strip()
                    
                    if line.lower() == 'end':
                        break
                    elif line.lower() in ['quit', 'exit', 'ì¢…ë£Œ', 'q']:
                        print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        return
                    elif line.lower() in ['cancel', 'ì·¨ì†Œ', 'c']:
                        print("âŒ ì§ˆë¬¸ ì…ë ¥ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                        break
                    elif line.lower() == 'clear':
                        query_lines = []
                        line_count = 0
                        print("ğŸ—‘ï¸  ì…ë ¥ ë‚´ìš©ì´ ì§€ì›Œì¡ŒìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•˜ì„¸ìš”.")
                        continue
                    # íˆìŠ¤í† ë¦¬ ì œì–´ ëª…ë ¹ì–´ë“¤
                    elif line.lower() == 'disable_history':
                        conversation_history.disable_history()
                        continue
                    elif line.lower() == 'enable_history':
                        conversation_history.enable_history()
                        continue
                    elif line.lower() == 'clear_history':
                        conversation_history.clear_history()
                        continue
                    elif line.lower() == 'reset_conversation':
                        conversation_history.reset_conversation()
                        continue
                    elif line.lower() == 'clear_and_disable':
                        conversation_history.clear_and_disable()
                        continue
                    elif line.lower() == 'remove_last':
                        conversation_history.remove_last_exchange()
                        continue
                    elif line.lower().startswith('remove_history:'):
                        try:
                            index = int(line.split(':', 1)[1].strip()) - 1
                            conversation_history.remove_exchange_by_index(index)
                        except (ValueError, IndexError):
                            print("âŒ í˜•ì‹: remove_history:ë²ˆí˜¸ (ì˜ˆ: remove_history:1)")
                        continue
                    elif line.lower() == 'history_status':
                        status = conversation_history.get_history_status()
                        print(f"\nğŸ“Š ëŒ€í™” íˆìŠ¤í† ë¦¬ ìƒíƒœ:")
                        print(f"  í™œì„±í™”: {'âœ…' if status['enabled'] else 'âŒ'}")
                        print(f"  ì €ì¥ëœ ëŒ€í™”: {status['count']}ê°œ")
                        print(f"  ìµœëŒ€ ì €ì¥: {status['max_history']}ê°œ")
                        print(f"  ì»¨í…ìŠ¤íŠ¸: {'ìˆìŒ' if status['has_context'] else 'ì—†ìŒ'}")
                        continue
                    elif line.lower() == 'show_history':
                        conversation_history.show_history()
                        continue
                    elif line.lower() == 'show_context':
                        if conversation_history.current_context:
                            print(f"\nğŸ“ í˜„ì¬ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸:")
                            print(f"{conversation_history.current_context}")
                        else:
                            print("ğŸ“ í˜„ì¬ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                        continue
                    else:
                        query_lines.append(line)
                
                # CANCELë¡œ ì·¨ì†Œëœ ê²½ìš° ë‹¤ìŒ ë£¨í”„ë¡œ
                if not query_lines:
                    continue
                
                # ì—¬ëŸ¬ ì¤„ì„ í•˜ë‚˜ì˜ ì§ˆë¬¸ìœ¼ë¡œ ê²°í•©
                query = " ".join(query_lines).strip()
                
                if not query:
                    print("âŒ ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    continue
                
                # ì…ë ¥ëœ ì§ˆë¬¸ í™•ì¸
                print(f"\nğŸ“ ì…ë ¥ëœ ì§ˆë¬¸ ({len(query_lines)}ì¤„):")
                print("-" * 40)
                for i, line in enumerate(query_lines, 1):
                    print(f"  {i}. {line}")
                print("-" * 40)
                print(f"ê²°í•©ëœ ì§ˆë¬¸: {query}")
                print("-" * 40)
                
                # íˆìŠ¤í† ë¦¬ ìƒíƒœ í‘œì‹œ
                status = conversation_history.get_history_status()
                if status['enabled']:
                    print(f"ğŸ’¾ íˆìŠ¤í† ë¦¬ ìƒíƒœ: í™œì„±í™” (ì €ì¥ë¨: {status['count']}ê°œ)")
                else:
                    print(f"ğŸš« íˆìŠ¤í† ë¦¬ ìƒíƒœ: ë¹„í™œì„±í™” (ì €ì¥ë˜ì§€ ì•ŠìŒ)")
                print("-" * 40)
                

                
                # ì´ì „ ëŒ€í™” ì»¨í…ìŠ¤íŠ¸ í™•ì¸ ë° ì ìš©
                relevant_context = conversation_history.get_relevant_context(query)
                if relevant_context:
                    print(f"\nğŸ”„ ê´€ë ¨ ì´ì „ ì»¨í…ìŠ¤íŠ¸ ë°œê²¬:")
                    print(f"  {relevant_context}")
                    print("-" * 50)
                
                print(f"\nğŸ¤– ì…ë ¥ëœ ì§ˆë¬¸: {query}")
                print("-" * 50)
                
                # ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰
                print("ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ìˆ˜í–‰ ì¤‘...")
                retrieved_docs_with_scores = enhanced_rag.search_documents(query, top_k=5)
                retrieved_docs = [doc for doc, _ in retrieved_docs_with_scores]
                print(f"ğŸ“š ê²€ìƒ‰ëœ ê´€ë ¨ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}")
                
                # ìœ ì‚¬ë„ ì ìˆ˜ ë¶„ì„
                print("\nğŸ” ìœ ì‚¬ë„ ì ìˆ˜ ë¶„ì„:")
                print("=" * 60)
                for i, (doc, score) in enumerate(retrieved_docs_with_scores, 1):
                    print(f"\nğŸ“‹ ë¬¸ì„œ {i} (ìœ ì‚¬ë„ ì ìˆ˜: {score:.4f}):")
                    print(f"   í˜ì´ì§€: {doc.metadata.get('page', 'N/A')}")
                    print(f"   ì†ŒìŠ¤: {doc.metadata.get('source', 'N/A')}")
                    print(f"   ë‚´ìš© ê¸¸ì´: {len(doc.page_content)}ì")
                    print(f"   ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {doc.page_content[:200]}...")
                    print("-" * 40)
                print("=" * 60)
                
                # ìœ ì‚¬ë„ ì ìˆ˜ í•´ì„
                print("\nğŸ’¡ ìœ ì‚¬ë„ ì ìˆ˜ í•´ì„:")
                print("   - ì ìˆ˜ê°€ ë‚®ì„ìˆ˜ë¡ ë” ìœ ì‚¬í•¨ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)")
                print("   - ì ìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ ëœ ìœ ì‚¬í•¨")
                
                # ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ì°¾ê¸°
                best_match = min(retrieved_docs_with_scores, key=lambda x: x[1])
                print(f"\nğŸ† ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ: ë¬¸ì„œ {retrieved_docs_with_scores.index(best_match) + 1} (ì ìˆ˜: {best_match[1]:.4f})")
                
                # ì „ì²´ ë¬¸ì„œ ë‚´ìš© ì¶œë ¥
                print("\nğŸ“„ ì „ì²´ ë¬¸ì„œ ë‚´ìš©:")
                print("=" * 60)
                for i, (doc, score) in enumerate(retrieved_docs_with_scores, 1):
                    print(f"\nğŸ“‹ ë¬¸ì„œ {i} (ìœ ì‚¬ë„ ì ìˆ˜: {score:.4f}):")
                    print(f"   ë‚´ìš©: {doc.page_content}")
                    print("-" * 40)
                print("=" * 60)

                # ì‹¤ì œ ì§ˆì˜ì‘ë‹µ ì‹¤í–‰
                print("ğŸ§  AI ì‘ë‹µ ìƒì„± ì¤‘...")
                
                # ìµœì¢… ì§ˆì˜ ë¡œê·¸ ì¶œë ¥
                print("\nğŸ“ ìµœì¢… ì§ˆì˜ ë¡œê·¸:")
                print("=" * 60)
                print(f"ì›ë³¸ ì§ˆë¬¸: {query}")
                print(f"ê²€ìƒ‰ëœ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}")
                print(f"ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {sum(len(doc.page_content) for doc in retrieved_docs)}ì")
                print(f"í‰ê·  ë¬¸ì„œ ê¸¸ì´: {sum(len(doc.page_content) for doc in retrieved_docs) // len(retrieved_docs) if retrieved_docs else 0}ì")
                print("-" * 60)
                
                # ê²€ìƒ‰ëœ ë¬¸ì„œ ìš”ì•½
                print("ğŸ“š ê²€ìƒ‰ëœ ë¬¸ì„œ ìš”ì•½:")
                for i, (doc, score) in enumerate(retrieved_docs_with_scores, 1):
                    print(f"  ë¬¸ì„œ {i} (ìœ ì‚¬ë„: {score:.4f}): {doc.page_content[:100]}...")
                print("=" * 60)
                
                # ì»¨í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ì§ˆë¬¸ ìƒì„±
                context_query = conversation_history.get_context_for_query(query)
                
                # RAG ì²´ì¸ì— ì „ë‹¬ë˜ëŠ” ì •ë³´
                print("ğŸ§  RAG ì²´ì¸ ì…ë ¥ ì •ë³´:")
                print(f"  - ì›ë³¸ ì§ˆë¬¸: {query}")
                if conversation_history.current_context:
                    print(f"  - ì´ì „ ì»¨í…ìŠ¤íŠ¸: {conversation_history.current_context[:100]}...")
                print(f"  - ì»¨í…ìŠ¤íŠ¸ ë¬¸ì„œ ìˆ˜: {len(retrieved_docs)}")
                print(f"  - ì´ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {sum(len(doc.page_content) for doc in retrieved_docs)}ì")
                print(f"  - ì‚¬ìš© ëª¨ë¸: Gemini 2.0 Flash")
                print(f"  - Temperature: 0.9")
                print("=" * 60)
                
                # RAG ì²´ì¸ ì‹¤í–‰ (ì»¨í…ìŠ¤íŠ¸ í¬í•¨)
                ai_message = qa_chain({"query": context_query})

                print("\n" + "=" * 50)
                print("âœ… ìµœì¢… ì‘ë‹µ:")
                print(ai_message['result'])
                print("=" * 50)
                
                # ëŒ€í™” íˆìŠ¤í† ë¦¬ì— êµí™˜ ì¶”ê°€
                conversation_history.add_exchange(query, ai_message['result'], retrieved_docs_with_scores)

            except KeyboardInterrupt:
                print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                return
            except Exception as e:
                print(f"âŒ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print("   ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
                continue
        
    except FileNotFoundError:
        print("âŒ tax.docx íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— tax.docx íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("   API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()